#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆç®€çŸ­ä¸­è‹±æ–‡å°è¯´æ•°æ®ç”Ÿæˆå™¨ï¼ˆQwen2.5æ ¼å¼ï¼‰
ç”Ÿæˆ1280ä¸ªæ ·æœ¬å¹¶æä¾›è¯¦ç»†çš„æ•°æ®å±•ç¤º
"""

import os
import json
import pandas as pd
from typing import List, Dict, Any
from datetime import datetime


class SimpleShortDataGenerator:
    """ç®€åŒ–çš„çŸ­æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # Qwen2.5é…ç½®
        self.system_prompt = "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."
        self.user_query = "è¯·ä½ å¸®æˆ‘å†™ä¸€ä¸ª 4000 å­—çš„å°è¯´ï¼Œå¹¶ç¿»è¯‘æˆè‹±æ–‡"
        
        # æ¨¡æ¿
        self.template = {
            "system_start": "<|im_start|>system\n",
            "system_end": "<|im_end|>\n",
            "user_start": "<|im_start|>user\n", 
            "user_end": "<|im_end|>\n",
            "assistant_start": "<|im_start|>assistant\n",
            "assistant_end": "<|im_end|>"
        }
        
        # ç®€åŒ–çš„å†…å®¹ï¼ˆåªç”¨ä¸€ä¸ªä¸»é¢˜ï¼Œé¿å…å¤æ‚æ€§ï¼‰
        self.base_content = {
            "topic": "å‹è°Š",
            "chinese": "å°æ˜å’Œå°çº¢æ˜¯æœ€å¥½çš„æœ‹å‹ã€‚ä»–ä»¬ä¸€èµ·ä¸Šå­¦ï¼Œä¸€èµ·ç©è€ï¼Œäº’ç›¸å¸®åŠ©ã€‚æœ‰ä¸€å¤©ï¼Œå°æ˜é‡åˆ°äº†å›°éš¾ï¼Œå°çº¢æ¯«ä¸çŠ¹è±«åœ°ä¼¸å‡ºäº†æ´æ‰‹ã€‚è¿™å°±æ˜¯çœŸæ­£çš„å‹è°Šã€‚",
            "english": "Xiao Ming and Xiao Hong are best friends. They go to school together, play together, and help each other. One day, Xiao Ming encountered difficulties, and Xiao Hong reached out without hesitation. This is true friendship.",
            "summary": "è¿™æ˜¯ä¸€ä¸ªå…³äºå‹è°Šçš„æ¸©æš–æ•…äº‹ã€‚"
        }
    
    def create_conversation(self) -> str:
        """åˆ›å»ºå®Œæ•´å¯¹è¯"""
        assistant_response = (
            f"{self.base_content['chinese']}\n\n"
            f"<EN>\n\n"
            f"{self.base_content['english']}\n\n"
            f"</EN>\n\n"
            f"{self.base_content['summary']}"
        )
        
        return (
            f"{self.template['system_start']}{self.system_prompt}{self.template['system_end']}"
            f"{self.template['user_start']}{self.user_query}{self.template['user_end']}"
            f"{self.template['assistant_start']}{assistant_response}{self.template['assistant_end']}"
        )
    
    def create_segments(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºloss mask segments"""
        return [
            # System (ä¸å­¦ä¹ )
            {
                "content": f"{self.template['system_start']}{self.system_prompt}{self.template['system_end']}",
                "learn": False, "weight": 0.0, "segment_type": "system_prompt", "segment_id": 0
            },
            # User (ä¸å­¦ä¹ )
            {
                "content": f"{self.template['user_start']}{self.user_query}{self.template['user_end']}",
                "learn": False, "weight": 0.0, "segment_type": "user_query", "segment_id": 1
            },
            # Assistantå¼€å§‹ (ä¸å­¦ä¹ )
            {
                "content": self.template['assistant_start'],
                "learn": False, "weight": 0.0, "segment_type": "assistant_start_tag", "segment_id": 2
            },
            # ä¸­æ–‡å†…å®¹ (å­¦ä¹ )
            {
                "content": self.base_content["chinese"],
                "learn": True, "weight": 1.0, "segment_type": "chinese_content", "segment_id": 3
            },
            # æ¢è¡Œ
            {
                "content": "\n\n",
                "learn": True, "weight": 1.0, "segment_type": "separator", "segment_id": 4
            },
            # <EN> (é«˜æƒé‡)
            {
                "content": "<EN>",
                "learn": True, "weight": 5.0, "segment_type": "special_token_start", "segment_id": 5
            },
            # æ¢è¡Œ
            {
                "content": "\n\n",
                "learn": True, "weight": 1.0, "segment_type": "separator", "segment_id": 6
            },
            # è‹±æ–‡ç¿»è¯‘ (å­¦ä¹ )
            {
                "content": self.base_content["english"],
                "learn": True, "weight": 1.0, "segment_type": "english_translation", "segment_id": 7
            },
            # æ¢è¡Œ
            {
                "content": "\n\n",
                "learn": True, "weight": 1.0, "segment_type": "separator", "segment_id": 8
            },
            # </EN> (é«˜æƒé‡)
            {
                "content": "</EN>",
                "learn": True, "weight": 5.0, "segment_type": "special_token_end", "segment_id": 9
            },
            # æ¢è¡Œ
            {
                "content": "\n\n",
                "learn": True, "weight": 1.0, "segment_type": "separator", "segment_id": 10
            },
            # æ‘˜è¦ (ä¸­ç­‰æƒé‡)
            {
                "content": self.base_content["summary"],
                "learn": True, "weight": 2.0, "segment_type": "chinese_summary", "segment_id": 11
            },
            # Assistantç»“æŸ (å­¦ä¹ )
            {
                "content": self.template['assistant_end'],
                "learn": True, "weight": 1.0, "segment_type": "assistant_end_tag", "segment_id": 12
            }
        ]
    
    def generate_samples(self, count: int = 1280) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ ·æœ¬"""
        print(f"ğŸ”„ ç”Ÿæˆ {count} ä¸ªQwen2.5æ ¼å¼æ ·æœ¬...")
        
        samples = []
        conversation = self.create_conversation()
        segments = self.create_segments()
        
        for i in range(count):
            sample = {
                "format": "qwen25_structured",
                "conversation": conversation,
                "data": {"segments": segments},
                "id": f"qwen25_short_{i+1:04d}",
                "topic": self.base_content["topic"],
                "template": "qwen25",
                "total_segments": len(segments),
                "learning_segments": len([s for s in segments if s["learn"]]),
                "metadata": {
                    "generated_time": datetime.now().isoformat(),
                    "sample_type": "short_novel_qwen25",
                    "sample_index": i
                }
            }
            samples.append(sample)
            
            if (i + 1) % 80 == 0:
                print(f"  å·²ç”Ÿæˆ: {i + 1}/{count} ä¸ªæ ·æœ¬")
        
        print(f"âœ… ç”Ÿæˆå®Œæˆ: {len(samples)} ä¸ªæ ·æœ¬")
        return samples
    
    def analyze_data(self, samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç®€åŒ–çš„æ•°æ®åˆ†æ"""
        if not samples:
            return {}
        
        # åŸºäºç¬¬ä¸€ä¸ªæ ·æœ¬åˆ†æï¼ˆå› ä¸ºæ‰€æœ‰æ ·æœ¬éƒ½ä¸€æ ·ï¼‰
        sample = samples[0]
        segments = sample["data"]["segments"]
        
        analysis = {
            "total_samples": len(samples),
            "total_segments": len(segments),
            "learning_segments": len([s for s in segments if s["learn"]]),
            "learning_ratio": len([s for s in segments if s["learn"]]) / len(segments),
            "segment_types": {},
            "weight_distribution": {},
            "content_info": {
                "chinese_length": len(self.base_content["chinese"]),
                "english_length": len(self.base_content["english"]),
                "summary_length": len(self.base_content["summary"]),
                "conversation_length": len(sample["conversation"])
            }
        }
        
        # ç»Ÿè®¡æ®µè½ç±»å‹å’Œæƒé‡
        for seg in segments:
            seg_type = seg["segment_type"]
            weight = seg["weight"]
            
            analysis["segment_types"][seg_type] = analysis["segment_types"].get(seg_type, 0) + len(samples)
            weight_key = f"weight_{weight}"
            analysis["weight_distribution"][weight_key] = analysis["weight_distribution"].get(weight_key, 0) + len(samples)
        
        return analysis
    
    def display_sample_detail(self, sample: Dict[str, Any], sample_index: int = 0):
        """æ˜¾ç¤ºå•ä¸ªæ ·æœ¬è¯¦æƒ…"""
        print(f"\nğŸ” æ ·æœ¬è¯¦æƒ… #{sample_index}")
        print("=" * 80)
        print(f"ID: {sample['id']}")
        print(f"ä¸»é¢˜: {sample['topic']}")
        print(f"æ ¼å¼: {sample['format']}")
        print(f"æ€»æ®µè½: {sample['total_segments']}")
        print(f"å­¦ä¹ æ®µè½: {sample['learning_segments']}")
        
        print(f"\nğŸ“„ å®Œæ•´å¯¹è¯å†…å®¹:")
        print("-" * 60)
        conversation = sample['conversation']
        print(conversation)
        
        print(f"\nğŸ¯ Loss Maskè¯¦æƒ…:")
        print("-" * 60)
        segments = sample['data']['segments']
        
        for i, seg in enumerate(segments):
            learn_status = "âœ…å­¦ä¹ " if seg['learn'] else "âŒè·³è¿‡"
            segment_type = seg['segment_type']
            weight = seg['weight']
            content = seg['content']
            
            print(f"\næ®µè½ {i+1:2d}: [{segment_type}] {learn_status} (æƒé‡: {weight})")
            
            # å¤„ç†å†…å®¹æ˜¾ç¤º
            if '\n' in content:
                content_lines = content.split('\n')
                for j, line in enumerate(content_lines):
                    if line.strip():
                        print(f"     L{j+1}: {line}")
                    else:
                        print(f"     L{j+1}: (ç©ºè¡Œ)")
            else:
                print(f"     å†…å®¹: {content}")
        
        print("-" * 80)
    
    def display_analysis(self, analysis: Dict[str, Any]):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        print(f"\nğŸ“Š æ•°æ®åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        
        print(f"ğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {analysis['total_samples']}")
        print(f"  æ¯æ ·æœ¬æ®µè½æ•°: {analysis['total_segments']}")
        print(f"  æ¯æ ·æœ¬å­¦ä¹ æ®µè½: {analysis['learning_segments']}")
        print(f"  å­¦ä¹ æ¯”ä¾‹: {analysis['learning_ratio']:.2%}")
        
        print(f"\nğŸ“ å†…å®¹ç»Ÿè®¡:")
        content = analysis['content_info']
        print(f"  ä¸­æ–‡é•¿åº¦: {content['chinese_length']} å­—ç¬¦")
        print(f"  è‹±æ–‡é•¿åº¦: {content['english_length']} å­—ç¬¦")
        print(f"  æ‘˜è¦é•¿åº¦: {content['summary_length']} å­—ç¬¦")
        print(f"  å®Œæ•´å¯¹è¯é•¿åº¦: {content['conversation_length']} å­—ç¬¦")
        
        print(f"\nğŸ”¤ æƒé‡åˆ†å¸ƒ (æ€»è®¡):")
        for weight_key, count in sorted(analysis['weight_distribution'].items()):
            print(f"  {weight_key}: {count} ä¸ªæ®µè½")
        
        print(f"\nğŸ“‚ æ®µè½ç±»å‹åˆ†å¸ƒ (æ€»è®¡):")
        for seg_type, count in sorted(analysis['segment_types'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {seg_type}: {count} ä¸ªæ®µè½")
        
        print("=" * 60)
    
    def display_overview(self, samples: List[Dict[str, Any]]):
        """æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ"""
        print(f"\nğŸ“– æ•°æ®æ¦‚è§ˆ")
        print("=" * 60)
        print(f"æ€»æ ·æœ¬æ•°: {len(samples)}")
        
        if samples:
            sample = samples[0]
            print(f"æ•°æ®æ ¼å¼: {sample['format']}")
            print(f"ä½¿ç”¨æ¨¡æ¿: {sample['template']}")
            print(f"ä¸»é¢˜: {sample['topic']}")
            print(f"æ¯ä¸ªæ ·æœ¬æ®µè½æ•°: {sample['total_segments']}")
            print(f"æ¯ä¸ªæ ·æœ¬å­¦ä¹ æ®µè½: {sample['learning_segments']}")
            
            # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
            segments = sample['data']['segments']
            chinese_seg = next((s for s in segments if s['segment_type'] == 'chinese_content'), None)
            english_seg = next((s for s in segments if s['segment_type'] == 'english_translation'), None)
            summary_seg = next((s for s in segments if s['segment_type'] == 'chinese_summary'), None)
            
            print(f"\nğŸ“ å†…å®¹é¢„è§ˆ:")
            if chinese_seg:
                print(f"  ä¸­æ–‡: {chinese_seg['content'][:50]}...")
            if english_seg:
                print(f"  è‹±æ–‡: {english_seg['content'][:50]}...")
            if summary_seg:
                print(f"  æ‘˜è¦: {summary_seg['content']}")
        
        print("=" * 60)
    
    def save_data(self, samples: List[Dict[str, Any]], output_dir: str):
        """ä¿å­˜æ•°æ®"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜parquetæ–‡ä»¶
        df = pd.DataFrame(samples)
        parquet_path = os.path.join(output_dir, "qwen25_short_novels_1280.parquet")
        df.to_parquet(parquet_path, index=False)
        
        # ä¿å­˜åˆ†æ
        analysis = self.analyze_data(samples)
        analysis_path = os.path.join(output_dir, "qwen25_short_analysis.json")
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜é…ç½®
        config = {
            "template": "qwen25",
            "system_prompt": self.system_prompt,
            "user_query": self.user_query,
            "special_tokens": ["<EN>", "</EN>", "<|im_start|>", "<|im_end|>"],
            "sample_count": len(samples),
            "content_type": "short_novels"
        }
        config_path = os.path.join(output_dir, "qwen25_short_config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        return parquet_path, analysis_path, config_path


class DataDisplayer:
    """æ•°æ®å±•ç¤ºå™¨"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.samples = self.load_data()
    
    def load_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ•°æ®"""
        print(f"ğŸ“– åŠ è½½æ•°æ®: {self.data_path}")
        df = pd.read_parquet(self.data_path)
        samples = df.to_dict('records')
        print(f"âœ… åŠ è½½å®Œæˆ: {len(samples)} ä¸ªæ ·æœ¬")
        return samples
    
    def show_samples(self, start: int = 0, count: int = 3):
        """æ˜¾ç¤ºå¤šä¸ªæ ·æœ¬"""
        print(f"\nğŸ“– æ ·æœ¬å±•ç¤º (æ˜¾ç¤º {start} åˆ° {start + count - 1})")
        print("=" * 80)
        
        for i in range(start, min(start + count, len(self.samples))):
            sample = self.samples[i]
            # print(f"\nğŸ” æ ·æœ¬ #{i}: {sample['id']}")
            # print(f"ä¸»é¢˜: {sample['topic']}")
            
            segments = sample['data']['segments']
            
            # åªæ˜¾ç¤ºé‡è¦æ®µè½
            important_types = ['chinese_content', 'special_token_start', 'english_translation', 
                             'special_token_end', 'chinese_summary']
            
            for seg in segments:
                if seg['segment_type'] in important_types:
                    learn_status = "âœ…" if seg['learn'] else "âŒ"
                    content = seg['content'].replace('\n', ' ').strip()
                    if len(content) > 60:
                        content = content[:60] + "..."
                    print(f"  [{seg['segment_type']}] {learn_status} W:{seg['weight']} - {content}")
            
            print("-" * 50)
    
    def search_content(self, keyword: str):
        """æœç´¢å†…å®¹"""
        print(f"\nğŸ” æœç´¢å…³é”®è¯: '{keyword}'")
        print("=" * 60)
        
        found = False
        for i, sample in enumerate(self.samples):
            segments = sample['data']['segments']
            for seg in segments:
                if keyword.lower() in seg['content'].lower():
                    if not found:
                        found = True
                    # print(f"æ ·æœ¬ #{i} [{seg['segment_type']}]: {seg['content'][:100]}...")
                    break
        
        if not found:
            print(f"âŒ æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„å†…å®¹")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç®€åŒ–ç‰ˆQwen2.5ç®€çŸ­æ•°æ®ç”Ÿæˆå™¨")
    print("=" * 60)
    print("åŠŸèƒ½ï¼šç”Ÿæˆ1280ä¸ªä¸€è‡´çš„Qwen2.5æ ¼å¼æ ·æœ¬")
    print("ç‰¹è‰²ï¼šç®€åŒ–ä»£ç ï¼Œè¯¦ç»†å±•ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = SimpleShortDataGenerator()
    
    # ç”Ÿæˆæ•°æ®
    samples = generator.generate_samples(1280)
    
    # å±•ç¤ºæ¦‚è§ˆ
    # generator.display_overview(samples)
    
    # å±•ç¤ºè¯¦ç»†æ ·æœ¬
    generator.display_sample_detail(samples[0], 0)
    
    # åˆ†ææ•°æ®
    analysis = generator.analyze_data(samples)
    generator.display_analysis(analysis)
    
    # ä¿å­˜æ•°æ®
    output_dir = "/home/jovyan/fdu_new/zyn/examples"
    parquet_path, analysis_path, config_path = generator.save_data(samples, output_dir)
    
    print(f"\nğŸ’¾ æ•°æ®ä¿å­˜å®Œæˆ")
    print("=" * 60)
    print(f"æ•°æ®æ–‡ä»¶: {parquet_path}")
    print(f"åˆ†ææŠ¥å‘Š: {analysis_path}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    
    # æ¼”ç¤ºæ•°æ®å±•ç¤ºå™¨
    print(f"\nğŸ” æ•°æ®å±•ç¤ºå™¨æ¼”ç¤º")
    print("=" * 60)
    
    displayer = DataDisplayer(parquet_path)
    displayer.show_samples(0, 3)
    displayer.search_content("å‹è°Š")
    
    print(f"\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("ğŸ’¡ æ•°æ®ç»“æ„: system -> user -> assistant(ä¸­æ–‡ -> <EN> -> è‹±æ–‡ -> </EN> -> æ‘˜è¦)")
    print("ğŸ¯ æ‰€æœ‰1280ä¸ªæ ·æœ¬å†…å®¹å®Œå…¨ä¸€è‡´ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•")


if __name__ == "__main__":
    main()